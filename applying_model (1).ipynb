{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name - Ishita Sharma\n",
    "CWID - 50224923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries required in the data for the application of the model\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from pandas.plotting import scatter_matrix\n",
    "from scipy import stats\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
      "0      842302          1       17.990         10.38          122.80   \n",
      "1      842517          1       20.570         17.77          132.90   \n",
      "2    84300903          1       19.690         21.25          130.00   \n",
      "3    84348301          1       11.420         20.38           77.58   \n",
      "4    84358402          1       20.290         14.34          135.10   \n",
      "5      843786          1       12.450         15.70           82.57   \n",
      "6      844359          1       18.250         19.98          119.60   \n",
      "7    84458202          1       13.710         20.83           90.20   \n",
      "8      844981          1       13.000         21.82           87.50   \n",
      "9    84501001          1       12.460         24.04           83.97   \n",
      "10     845636          1       16.020         23.24          102.70   \n",
      "11   84610002          1       15.780         17.89          103.60   \n",
      "12     846226          1       19.170         24.80          132.40   \n",
      "13     846381          1       15.850         23.95          103.70   \n",
      "14   84667401          1       13.730         22.61           93.60   \n",
      "15   84799002          1       14.540         27.54           96.73   \n",
      "16     848406          1       14.680         20.13           94.74   \n",
      "17   84862001          1       16.130         20.68          108.10   \n",
      "18     849014          1       19.810         22.15          130.00   \n",
      "19    8510426          0       13.540         14.36           87.46   \n",
      "20    8510653          0       13.080         15.71           85.63   \n",
      "21    8510824          0        9.504         12.44           60.34   \n",
      "22    8511133          1       15.340         14.26          102.50   \n",
      "23     851509          1       21.160         23.04          137.20   \n",
      "24     852552          1       16.650         21.38          110.00   \n",
      "25     852631          1       17.140         16.40          116.00   \n",
      "26     852763          1       14.580         21.53           97.41   \n",
      "27     852781          1       18.610         20.25          122.10   \n",
      "28     852973          1       15.300         25.27          102.40   \n",
      "29     853201          1       17.570         15.05          115.00   \n",
      "..        ...        ...          ...           ...             ...   \n",
      "539    921362          0        7.691         25.44           48.34   \n",
      "540    921385          0       11.540         14.44           74.65   \n",
      "541    921386          0       14.470         24.99           95.81   \n",
      "542    921644          0       14.740         25.42           94.70   \n",
      "543    922296          0       13.210         28.06           84.88   \n",
      "544    922297          0       13.870         20.70           89.77   \n",
      "545    922576          0       13.620         23.23           87.19   \n",
      "546    922577          0       10.320         16.35           65.31   \n",
      "547    922840          0       10.260         16.58           65.85   \n",
      "548    923169          0        9.683         19.34           61.05   \n",
      "549    923465          0       10.820         24.21           68.89   \n",
      "550    923748          0       10.860         21.48           68.51   \n",
      "551    923780          0       11.130         22.44           71.49   \n",
      "552    924084          0       12.770         29.43           81.35   \n",
      "553    924342          0        9.333         21.94           59.01   \n",
      "554    924632          0       12.880         28.92           82.50   \n",
      "555    924934          0       10.290         27.61           65.67   \n",
      "556    924964          0       10.160         19.59           64.73   \n",
      "557    925236          0        9.423         27.88           59.26   \n",
      "558    925277          0       14.590         22.68           96.39   \n",
      "559    925291          0       11.510         23.93           74.52   \n",
      "560    925292          0       14.050         27.15           91.38   \n",
      "561    925311          0       11.200         29.37           70.67   \n",
      "562    925622          1       15.220         30.62          103.40   \n",
      "563    926125          1       20.920         25.09          143.00   \n",
      "564    926424          1       21.560         22.39          142.00   \n",
      "565    926682          1       20.130         28.25          131.20   \n",
      "566    926954          1       16.600         28.08          108.30   \n",
      "567    927241          1       20.600         29.33          140.10   \n",
      "568     92751          0        7.760         24.54           47.92   \n",
      "\n",
      "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
      "0       1001.0          0.11840           0.27760        0.300100   \n",
      "1       1326.0          0.08474           0.07864        0.086900   \n",
      "2       1203.0          0.10960           0.15990        0.197400   \n",
      "3        386.1          0.14250           0.28390        0.241400   \n",
      "4       1297.0          0.10030           0.13280        0.198000   \n",
      "5        477.1          0.12780           0.17000        0.157800   \n",
      "6       1040.0          0.09463           0.10900        0.112700   \n",
      "7        577.9          0.11890           0.16450        0.093660   \n",
      "8        519.8          0.12730           0.19320        0.185900   \n",
      "9        475.9          0.11860           0.23960        0.227300   \n",
      "10       797.8          0.08206           0.06669        0.032990   \n",
      "11       781.0          0.09710           0.12920        0.099540   \n",
      "12      1123.0          0.09740           0.24580        0.206500   \n",
      "13       782.7          0.08401           0.10020        0.099380   \n",
      "14       578.3          0.11310           0.22930        0.212800   \n",
      "15       658.8          0.11390           0.15950        0.163900   \n",
      "16       684.5          0.09867           0.07200        0.073950   \n",
      "17       798.8          0.11700           0.20220        0.172200   \n",
      "18      1260.0          0.09831           0.10270        0.147900   \n",
      "19       566.3          0.09779           0.08129        0.066640   \n",
      "20       520.0          0.10750           0.12700        0.045680   \n",
      "21       273.9          0.10240           0.06492        0.029560   \n",
      "22       704.4          0.10730           0.21350        0.207700   \n",
      "23      1404.0          0.09428           0.10220        0.109700   \n",
      "24       904.6          0.11210           0.14570        0.152500   \n",
      "25       912.7          0.11860           0.22760        0.222900   \n",
      "26       644.8          0.10540           0.18680        0.142500   \n",
      "27      1094.0          0.09440           0.10660        0.149000   \n",
      "28       732.4          0.10820           0.16970        0.168300   \n",
      "29       955.1          0.09847           0.11570        0.098750   \n",
      "..         ...              ...               ...             ...   \n",
      "539      170.4          0.08668           0.11990        0.092520   \n",
      "540      402.9          0.09984           0.11200        0.067370   \n",
      "541      656.4          0.08837           0.12300        0.100900   \n",
      "542      668.6          0.08275           0.07214        0.041050   \n",
      "543      538.4          0.08671           0.06877        0.029870   \n",
      "544      584.8          0.09578           0.10180        0.036880   \n",
      "545      573.2          0.09246           0.06747        0.029740   \n",
      "546      324.9          0.09434           0.04994        0.010120   \n",
      "547      320.8          0.08877           0.08066        0.043580   \n",
      "548      285.7          0.08491           0.05030        0.023370   \n",
      "549      361.6          0.08192           0.06602        0.015480   \n",
      "550      360.5          0.07431           0.04227        0.000000   \n",
      "551      378.4          0.09566           0.08194        0.048240   \n",
      "552      507.9          0.08276           0.04234        0.019970   \n",
      "553      264.0          0.09240           0.05605        0.039960   \n",
      "554      514.3          0.08123           0.05824        0.061950   \n",
      "555      321.4          0.09030           0.07658        0.059990   \n",
      "556      311.7          0.10030           0.07504        0.005025   \n",
      "557      271.3          0.08123           0.04971        0.000000   \n",
      "558      657.1          0.08473           0.13300        0.102900   \n",
      "559      403.5          0.09261           0.10210        0.111200   \n",
      "560      600.4          0.09929           0.11260        0.044620   \n",
      "561      386.0          0.07449           0.03558        0.000000   \n",
      "562      716.9          0.10480           0.20870        0.255000   \n",
      "563     1347.0          0.10990           0.22360        0.317400   \n",
      "564     1479.0          0.11100           0.11590        0.243900   \n",
      "565     1261.0          0.09780           0.10340        0.144000   \n",
      "566      858.1          0.08455           0.10230        0.092510   \n",
      "567     1265.0          0.11780           0.27700        0.351400   \n",
      "568      181.0          0.05263           0.04362        0.000000   \n",
      "\n",
      "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0               0.147100  ...        25.380          17.33           184.60   \n",
      "1               0.070170  ...        24.990          23.41           158.80   \n",
      "2               0.127900  ...        23.570          25.53           152.50   \n",
      "3               0.105200  ...        14.910          26.50            98.87   \n",
      "4               0.104300  ...        22.540          16.67           152.20   \n",
      "5               0.080890  ...        15.470          23.75           103.40   \n",
      "6               0.074000  ...        22.880          27.66           153.20   \n",
      "7               0.059850  ...        17.060          28.14           110.60   \n",
      "8               0.093530  ...        15.490          30.73           106.20   \n",
      "9               0.085430  ...        15.090          40.68            97.65   \n",
      "10              0.033230  ...        19.190          33.88           123.80   \n",
      "11              0.066060  ...        20.420          27.28           136.50   \n",
      "12              0.111800  ...        20.960          29.94           151.70   \n",
      "13              0.053640  ...        16.840          27.66           112.00   \n",
      "14              0.080250  ...        15.030          32.01           108.80   \n",
      "15              0.073640  ...        17.460          37.13           124.10   \n",
      "16              0.052590  ...        19.070          30.88           123.40   \n",
      "17              0.102800  ...        20.960          31.48           136.80   \n",
      "18              0.094980  ...        27.320          30.88           186.80   \n",
      "19              0.047810  ...        15.110          19.26            99.70   \n",
      "20              0.031100  ...        14.500          20.49            96.09   \n",
      "21              0.020760  ...        10.230          15.66            65.13   \n",
      "22              0.097560  ...        18.070          19.08           125.10   \n",
      "23              0.086320  ...        29.170          35.59           188.00   \n",
      "24              0.091700  ...        26.460          31.56           177.00   \n",
      "25              0.140100  ...        22.250          21.40           152.40   \n",
      "26              0.087830  ...        17.620          33.21           122.40   \n",
      "27              0.077310  ...        21.310          27.26           139.90   \n",
      "28              0.087510  ...        20.270          36.71           149.30   \n",
      "29              0.079530  ...        20.010          19.52           134.90   \n",
      "..                   ...  ...           ...            ...              ...   \n",
      "539             0.013640  ...         8.678          31.89            54.49   \n",
      "540             0.025940  ...        12.260          19.68            78.78   \n",
      "541             0.038900  ...        16.220          31.73           113.50   \n",
      "542             0.030270  ...        16.510          32.29           107.40   \n",
      "543             0.032750  ...        14.370          37.17            92.48   \n",
      "544             0.023690  ...        15.050          24.75            99.17   \n",
      "545             0.024430  ...        15.350          29.09            97.58   \n",
      "546             0.005495  ...        11.250          21.77            71.12   \n",
      "547             0.024380  ...        10.830          22.04            71.08   \n",
      "548             0.009615  ...        10.930          25.59            69.10   \n",
      "549             0.008160  ...        13.030          31.45            83.90   \n",
      "550             0.000000  ...        11.660          24.77            74.08   \n",
      "551             0.022570  ...        12.020          28.26            77.80   \n",
      "552             0.014990  ...        13.870          36.00            88.10   \n",
      "553             0.012820  ...         9.845          25.05            62.86   \n",
      "554             0.023430  ...        13.890          35.74            88.84   \n",
      "555             0.027380  ...        10.840          34.91            69.57   \n",
      "556             0.011160  ...        10.650          22.88            67.88   \n",
      "557             0.000000  ...        10.490          34.24            66.50   \n",
      "558             0.037360  ...        15.480          27.27           105.90   \n",
      "559             0.041050  ...        12.480          37.16            82.28   \n",
      "560             0.043040  ...        15.300          33.17           100.20   \n",
      "561             0.000000  ...        11.920          38.30            75.19   \n",
      "562             0.094290  ...        17.520          42.79           128.70   \n",
      "563             0.147400  ...        24.290          29.41           179.10   \n",
      "564             0.138900  ...        25.450          26.40           166.10   \n",
      "565             0.097910  ...        23.690          38.25           155.00   \n",
      "566             0.053020  ...        18.980          34.12           126.70   \n",
      "567             0.152000  ...        25.740          39.42           184.60   \n",
      "568             0.000000  ...         9.456          30.37            59.16   \n",
      "\n",
      "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0        2019.0           0.16220            0.66560          0.71190   \n",
      "1        1956.0           0.12380            0.18660          0.24160   \n",
      "2        1709.0           0.14440            0.42450          0.45040   \n",
      "3         567.7           0.20980            0.86630          0.68690   \n",
      "4        1575.0           0.13740            0.20500          0.40000   \n",
      "5         741.6           0.17910            0.52490          0.53550   \n",
      "6        1606.0           0.14420            0.25760          0.37840   \n",
      "7         897.0           0.16540            0.36820          0.26780   \n",
      "8         739.3           0.17030            0.54010          0.53900   \n",
      "9         711.4           0.18530            1.05800          1.10500   \n",
      "10       1150.0           0.11810            0.15510          0.14590   \n",
      "11       1299.0           0.13960            0.56090          0.39650   \n",
      "12       1332.0           0.10370            0.39030          0.36390   \n",
      "13        876.5           0.11310            0.19240          0.23220   \n",
      "14        697.7           0.16510            0.77250          0.69430   \n",
      "15        943.2           0.16780            0.65770          0.70260   \n",
      "16       1138.0           0.14640            0.18710          0.29140   \n",
      "17       1315.0           0.17890            0.42330          0.47840   \n",
      "18       2398.0           0.15120            0.31500          0.53720   \n",
      "19        711.2           0.14400            0.17730          0.23900   \n",
      "20        630.5           0.13120            0.27760          0.18900   \n",
      "21        314.9           0.13240            0.11480          0.08867   \n",
      "22        980.9           0.13900            0.59540          0.63050   \n",
      "23       2615.0           0.14010            0.26000          0.31550   \n",
      "24       2215.0           0.18050            0.35780          0.46950   \n",
      "25       1461.0           0.15450            0.39490          0.38530   \n",
      "26        896.9           0.15250            0.66430          0.55390   \n",
      "27       1403.0           0.13380            0.21170          0.34460   \n",
      "28       1269.0           0.16410            0.61100          0.63350   \n",
      "29       1227.0           0.12550            0.28120          0.24890   \n",
      "..          ...               ...                ...              ...   \n",
      "539       223.6           0.15960            0.30640          0.33930   \n",
      "540       457.8           0.13450            0.21180          0.17970   \n",
      "541       808.9           0.13400            0.42020          0.40400   \n",
      "542       826.4           0.10600            0.13760          0.16110   \n",
      "543       629.6           0.10720            0.13810          0.10620   \n",
      "544       688.6           0.12640            0.20370          0.13770   \n",
      "545       729.8           0.12160            0.15170          0.10490   \n",
      "546       384.9           0.12850            0.08842          0.04384   \n",
      "547       357.4           0.14610            0.22460          0.17830   \n",
      "548       364.2           0.11990            0.09546          0.09350   \n",
      "549       505.6           0.12040            0.16330          0.06194   \n",
      "550       412.3           0.10010            0.07348          0.00000   \n",
      "551       436.6           0.10870            0.17820          0.15640   \n",
      "552       594.7           0.12340            0.10640          0.08653   \n",
      "553       295.8           0.11030            0.08298          0.07993   \n",
      "554       595.7           0.12270            0.16200          0.24390   \n",
      "555       357.6           0.13840            0.17100          0.20000   \n",
      "556       347.3           0.12650            0.12000          0.01005   \n",
      "557       330.6           0.10730            0.07158          0.00000   \n",
      "558       733.5           0.10260            0.31710          0.36620   \n",
      "559       474.2           0.12980            0.25170          0.36300   \n",
      "560       706.7           0.12410            0.22640          0.13260   \n",
      "561       439.6           0.09267            0.05494          0.00000   \n",
      "562       915.0           0.14170            0.79170          1.17000   \n",
      "563      1819.0           0.14070            0.41860          0.65990   \n",
      "564      2027.0           0.14100            0.21130          0.41070   \n",
      "565      1731.0           0.11660            0.19220          0.32150   \n",
      "566      1124.0           0.11390            0.30940          0.34030   \n",
      "567      1821.0           0.16500            0.86810          0.93870   \n",
      "568       268.6           0.08996            0.06444          0.00000   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                 0.26540          0.4601                  0.11890  \n",
      "1                 0.18600          0.2750                  0.08902  \n",
      "2                 0.24300          0.3613                  0.08758  \n",
      "3                 0.25750          0.6638                  0.17300  \n",
      "4                 0.16250          0.2364                  0.07678  \n",
      "5                 0.17410          0.3985                  0.12440  \n",
      "6                 0.19320          0.3063                  0.08368  \n",
      "7                 0.15560          0.3196                  0.11510  \n",
      "8                 0.20600          0.4378                  0.10720  \n",
      "9                 0.22100          0.4366                  0.20750  \n",
      "10                0.09975          0.2948                  0.08452  \n",
      "11                0.18100          0.3792                  0.10480  \n",
      "12                0.17670          0.3176                  0.10230  \n",
      "13                0.11190          0.2809                  0.06287  \n",
      "14                0.22080          0.3596                  0.14310  \n",
      "15                0.17120          0.4218                  0.13410  \n",
      "16                0.16090          0.3029                  0.08216  \n",
      "17                0.20730          0.3706                  0.11420  \n",
      "18                0.23880          0.2768                  0.07615  \n",
      "19                0.12880          0.2977                  0.07259  \n",
      "20                0.07283          0.3184                  0.08183  \n",
      "21                0.06227          0.2450                  0.07773  \n",
      "22                0.23930          0.4667                  0.09946  \n",
      "23                0.20090          0.2822                  0.07526  \n",
      "24                0.20950          0.3613                  0.09564  \n",
      "25                0.25500          0.4066                  0.10590  \n",
      "26                0.27010          0.4264                  0.12750  \n",
      "27                0.14900          0.2341                  0.07421  \n",
      "28                0.20240          0.4027                  0.09876  \n",
      "29                0.14560          0.2756                  0.07919  \n",
      "..                    ...             ...                      ...  \n",
      "539               0.05000          0.2790                  0.10660  \n",
      "540               0.06918          0.2329                  0.08134  \n",
      "541               0.12050          0.3187                  0.10230  \n",
      "542               0.10950          0.2722                  0.06956  \n",
      "543               0.07958          0.2473                  0.06443  \n",
      "544               0.06845          0.2249                  0.08492  \n",
      "545               0.07174          0.2642                  0.06953  \n",
      "546               0.02381          0.2681                  0.07399  \n",
      "547               0.08333          0.2691                  0.09479  \n",
      "548               0.03846          0.2552                  0.07920  \n",
      "549               0.03264          0.3059                  0.07626  \n",
      "550               0.00000          0.2458                  0.06592  \n",
      "551               0.06413          0.3169                  0.08032  \n",
      "552               0.06498          0.2407                  0.06484  \n",
      "553               0.02564          0.2435                  0.07393  \n",
      "554               0.06493          0.2372                  0.07242  \n",
      "555               0.09127          0.2226                  0.08283  \n",
      "556               0.02232          0.2262                  0.06742  \n",
      "557               0.00000          0.2475                  0.06969  \n",
      "558               0.11050          0.2258                  0.08004  \n",
      "559               0.09653          0.2112                  0.08732  \n",
      "560               0.10480          0.2250                  0.08321  \n",
      "561               0.00000          0.1566                  0.05905  \n",
      "562               0.23560          0.4089                  0.14090  \n",
      "563               0.25420          0.2929                  0.09873  \n",
      "564               0.22160          0.2060                  0.07115  \n",
      "565               0.16280          0.2572                  0.06637  \n",
      "566               0.14180          0.2218                  0.07820  \n",
      "567               0.26500          0.4087                  0.12400  \n",
      "568               0.00000          0.2871                  0.07039  \n",
      "\n",
      "[569 rows x 32 columns]\n",
      "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302          1        17.99         10.38          122.80     1001.0   \n",
      "1    842517          1        20.57         17.77          132.90     1326.0   \n",
      "2  84300903          1        19.69         21.25          130.00     1203.0   \n",
      "3  84348301          1        11.42         20.38           77.58      386.1   \n",
      "4  84358402          1        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "0  ...         25.38          17.33           184.60      2019.0   \n",
      "1  ...         24.99          23.41           158.80      1956.0   \n",
      "2  ...         23.57          25.53           152.50      1709.0   \n",
      "3  ...         14.91          26.50            98.87       567.7   \n",
      "4  ...         22.54          16.67           152.20      1575.0   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  \n",
      "0          0.4601                  0.11890  \n",
      "1          0.2750                  0.08902  \n",
      "2          0.3613                  0.08758  \n",
      "3          0.6638                  0.17300  \n",
      "4          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "\n",
      "\n",
      "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "564  926424          1        21.56         22.39          142.00     1479.0   \n",
      "565  926682          1        20.13         28.25          131.20     1261.0   \n",
      "566  926954          1        16.60         28.08          108.30      858.1   \n",
      "567  927241          1        20.60         29.33          140.10     1265.0   \n",
      "568   92751          0         7.76         24.54           47.92      181.0   \n",
      "\n",
      "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "564          0.11100           0.11590         0.24390              0.13890   \n",
      "565          0.09780           0.10340         0.14400              0.09791   \n",
      "566          0.08455           0.10230         0.09251              0.05302   \n",
      "567          0.11780           0.27700         0.35140              0.15200   \n",
      "568          0.05263           0.04362         0.00000              0.00000   \n",
      "\n",
      "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "564  ...        25.450          26.40           166.10      2027.0   \n",
      "565  ...        23.690          38.25           155.00      1731.0   \n",
      "566  ...        18.980          34.12           126.70      1124.0   \n",
      "567  ...        25.740          39.42           184.60      1821.0   \n",
      "568  ...         9.456          30.37            59.16       268.6   \n",
      "\n",
      "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "564                0.2216          0.2060                  0.07115  \n",
      "565                0.1628          0.2572                  0.06637  \n",
      "566                0.1418          0.2218                  0.07820  \n",
      "567                0.2650          0.4087                  0.12400  \n",
      "568                0.0000          0.2871                  0.07039  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
      "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#loading the data \n",
    "#Doing some essential changes inorder to apply classifier to the model\n",
    "df = pd.read_csv(\"Breast_cancer_data.csv\",header = 0)\n",
    "df = df.replace({'B':0,'M':1})\n",
    "df = df.dropna(axis = 1)\n",
    "print(df)\n",
    "print(df.head())\n",
    "print()\n",
    "print()\n",
    "print(df.tail())\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here first of all to apply the train_test_split I made sure that I can combine the \n",
    "#independent data(features) in X\n",
    "#dependent data(predictor or target) in Y which is the diagnosis that is 'B' or 'M'\n",
    "#I used .values so that I can get the array(vector) so I can easily split the data in train and test\n",
    "X = df.iloc[:, 2:31].values \n",
    "Y = df.iloc[:, 1].values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data on train and test\n",
    "#Making the model ready for the train data processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing(Feature scaling)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling for my data so that the train and test data are better in the scale \n",
    "So that all the prediction on test data can be done with accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(X_train,Y_train):\n",
    "  \n",
    "  #Using Logistic Regression Algorithm to the Training Set\n",
    "    log_reg = LogisticRegression(random_state = 0,solver = 'lbfgs')\n",
    "    log_reg.fit(X_train, Y_train)\n",
    "  \n",
    "  #Using KNeighborsClassifier(Nearest Neighbor algorithm)\n",
    "  #help(KNeighborsClassifier)\n",
    "    knn_model = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    knn_model.fit(X_train, Y_train)\n",
    "\n",
    "  #Using SVC method to apply Support Vector Machine Algorithm\n",
    "  #in SVM we have many kernels so here I am using the linear and rbf\n",
    "    svc_linear = SVC(kernel = 'linear', random_state = 0)\n",
    "    svc_linear.fit(X_train, Y_train)\n",
    "    \n",
    "    svc_rbf = SVC(kernel = 'rbf', random_state = 0)\n",
    "    svc_rbf.fit(X_train, Y_train)\n",
    "\n",
    "    \n",
    "  #Using DecisionTreeClassifier(Decision Tree Algorithm)\n",
    "    Dec_tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    Dec_tree.fit(X_train, Y_train)\n",
    "\n",
    "  #Using RandomForestClassifier(one of the best consisdered classifier)\n",
    "    Rand_forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    Rand_forest.fit(X_train, Y_train)\n",
    "  \n",
    "  #print model accuracy on the training data.\n",
    "    #print(\"The Training accuracy of the model with different models is as follows:\")\n",
    "    print('[1]Logistic Regression:', log_reg.score(X_train, Y_train))\n",
    "    print('[2]KNearest Neighbor:', knn_model.score(X_train, Y_train))\n",
    "    print('[3]Support Vector Machine (Linear Classifier):', svc_linear.score(X_train, Y_train))\n",
    "    print('[4]Support Vector Machine (RBF Classifier):',svc_rbf.score(X_train, Y_train))\n",
    "    print('[5]Decision Tree Classifier: ', Dec_tree.score(X_train, Y_train))\n",
    "    print('[6]Random Forest Classifier:', Rand_forest.score(X_train, Y_train))\n",
    "  \n",
    "    return log_reg, knn_model, svc_linear,svc_rbf , Dec_tree, Rand_forest\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Logistic Regression: 0.9906103286384976\n",
      "[2]KNearest Neighbor: 0.9765258215962441\n",
      "[3]Support Vector Machine (Linear Classifier): 0.9882629107981221\n",
      "[4]Support Vector Machine (RBF Classifier): 0.9835680751173709\n",
      "[5]Decision Tree Classifier:  1.0\n",
      "[6]Random Forest Classifier: 0.9953051643192489\n"
     ]
    }
   ],
   "source": [
    " model = models(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see that usually the RandomForest Classifier is considered to be the best classifier \n",
    "but apparently the best classifier which can be used for the classification of the Malingant(M) and Bengin(B)\n",
    "is Decision Tree with the accuracy of perfect '1'\n",
    "Also this is the result with the sklearn library\n",
    "We can also compare it without the using of the sklearn library as well\n",
    "Usually the RandomForest is one of the type of the ensemble methods of the Decision Tree \n",
    "So therefore it is always best using for the categorical kind of data the Decision Tree Classifier\n",
    "\n",
    "\n",
    "After this I will apply the model to the test data and try to predict which is the goal of the whole model making \n",
    "such that I can make a Classification system\n",
    "I will first use Confusion Matrix(cm) so as to get the accuracy\n",
    "Then using the libraries of sklearn I can generate the classification report of the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86  4]\n",
      " [ 4 49]]\n",
      "\n",
      "Model[0] Testing Accuracy = \"0.9440559440559441!\"\n",
      "------------------------------------------\n",
      "\n",
      "[[89  1]\n",
      " [ 5 48]]\n",
      "\n",
      "Model[1] Testing Accuracy = \"0.958041958041958!\"\n",
      "------------------------------------------\n",
      "\n",
      "[[87  3]\n",
      " [ 2 51]]\n",
      "\n",
      "Model[2] Testing Accuracy = \"0.965034965034965!\"\n",
      "------------------------------------------\n",
      "\n",
      "[[88  2]\n",
      " [ 3 50]]\n",
      "\n",
      "Model[3] Testing Accuracy = \"0.965034965034965!\"\n",
      "------------------------------------------\n",
      "\n",
      "[[84  6]\n",
      " [ 1 52]]\n",
      "\n",
      "Model[4] Testing Accuracy = \"0.951048951048951!\"\n",
      "------------------------------------------\n",
      "\n",
      "[[87  3]\n",
      " [ 2 51]]\n",
      "\n",
      "Model[5] Testing Accuracy = \"0.965034965034965!\"\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using ConfusionMatrix\n",
    "#cm_log = confusion_matrix(Y_test, model[0].predict(X_test))\n",
    "#cm_knn = confusion_matrix(Y_test, model[1].predict(X_test))\n",
    "#cm_svm_lin = confusion_matrix(Y_test, model[3].predict(X_test))\n",
    "#cm_svm_rbf = confusion_matrix(Y_test,model[4].predict(X_test))\n",
    "#cm_DT = confusion_matrix(Y_test, model[5].predict(X_test))\n",
    "#cm_RandomForest = confusion_matrix(Y_test, model[6].predict(X_test))\n",
    "\n",
    "#It is always more conviennet to put all the model in for loop since we are finding the confusion matrics for all \n",
    "for m in range(len(model)):\n",
    "    cm = confusion_matrix(Y_test, model[m].predict(X_test))\n",
    "    True_Neg = cm[0][0]\n",
    "    True_Pos = cm[1][1]\n",
    "    False_Neg = cm[1][0]\n",
    "    False_Pos = cm[0][1]\n",
    "    \n",
    "    total = True_Neg+True_Pos+False_Neg+False_Pos\n",
    "    accuracy = (True_Neg + True_Pos)/total\n",
    "    print(cm)\n",
    "    print()\n",
    "    print('Model[{}] Testing Accuracy = \"{}!\"'.format(m, accuracy))\n",
    "    print('------------------------------------------')\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        90\n",
      "           1       0.92      0.92      0.92        53\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.94      0.94      0.94       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n",
      "0.9440559440559441\n",
      "\n",
      "Model  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        90\n",
      "           1       0.98      0.91      0.94        53\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.95      0.95       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n",
      "0.958041958041958\n",
      "\n",
      "Model  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        90\n",
      "           1       0.94      0.96      0.95        53\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n",
      "0.965034965034965\n",
      "\n",
      "Model  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        90\n",
      "           1       0.96      0.94      0.95        53\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.97      0.96       143\n",
      "\n",
      "0.965034965034965\n",
      "\n",
      "Model  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96        90\n",
      "           1       0.90      0.98      0.94        53\n",
      "\n",
      "    accuracy                           0.95       143\n",
      "   macro avg       0.94      0.96      0.95       143\n",
      "weighted avg       0.95      0.95      0.95       143\n",
      "\n",
      "0.951048951048951\n",
      "\n",
      "Model  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        90\n",
      "           1       0.94      0.96      0.95        53\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n",
      "0.965034965034965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#After this we can produce the classification report,for which the library I have added above in the first block\n",
    "\n",
    "for i in range(len(model)):\n",
    "  print('Model ',i)\n",
    "  #Check precision, recall, f1-score\n",
    "  print( classification_report(Y_test, model[i].predict(X_test)) )\n",
    "  #Another way to get the models accuracy on the test data\n",
    "  print( accuracy_score(Y_test, model[i].predict(X_test)))\n",
    "  print()#Print a new line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#based on the accuracy score (Random forest is the best classifier)\n",
    "pred = model[5].predict(X_test)\n",
    "print(pred)\n",
    "#Print a space\n",
    "print()\n",
    "#Print the actual values\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found the random forest is the best classifier\n",
    "After this I made another notebook in which I try doing feature selection with random forest classifier\n",
    "The notebook is named Feature_Selection using RandomForest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
